<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="format-detection" content="telephone=no"/><link href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.css" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/css/lightbox.css" rel="stylesheet"/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link href="/static/css/style.css" rel="stylesheet"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox-plus-jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              $('.ui.sidebar')
                .sidebar('attach events', '.sidebar.icon')

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><title class="next-head">Wesley Willett | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="Human-Computer Interaction, HCI, Information Visualization, University of Calgary, CHI, UIST" class="next-head"/><meta name="description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta property="og:title" content="Wesley Willett | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta property="og:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta property="og:site_name" content="University of Calgary Interactions Lab" class="next-head"/><meta property="og:url" content="https://ilab.ucalgary.ca/" class="next-head"/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/people/wesley-willett.jpg" class="next-head"/><meta property="og:type" content="website" class="next-head"/><meta name="twitter:title" content="Wesley Willett | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta name="twitter:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/people/wesley-willett.jpg" class="next-head"/><meta name="twitter:card" content="summary" class="next-head"/><meta name="twitter:site" content="@ucalgary" class="next-head"/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" class="next-head"/><link rel="preload" href="/_next/static/K2hp6SO31UL_wodvuo4Go/pages/person.js" as="script"/><link rel="preload" href="/_next/static/K2hp6SO31UL_wodvuo4Go/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.2ccf7861fac39e850a30.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-ceb4d64d798d2348aa74.js" as="script"/></head><body><div id="__next"><div><div><div class="ui right vertical sidebar menu"><a class="item" href="/">Home</a><a class="item" href="/publications">Publications</a><a class="item active" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a></div><div class="ui stackable secondary pointing container menu" style="border-bottom:none;margin-right:15%;font-size:1.1em"><div class="left menu"><a class="item" href="/"><b>UCalgary iLab</b></a></div><div class="right menu"><a class="item" href="/publications">Publications</a><a class="item active" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a><div class="toc item"><a href="/"><b>UCalgary iLab</b></a><i style="float:right" class="sidebar icon"></i></div></div></div></div><div class="ui stackable grid"><div class="one wide column"></div><div class="eleven wide column centered"><div id="person" class="category" style="text-align:center"><img class="ui circular image large-profile" src="/static/images/people/wesley-willett.jpg" style="margin:auto"/><h1>Wesley Willett</h1><p>Associate Professor</p><p><a href="http://www.wjwillett.net" target="_blank"><i class="fas fa-link fa-fw"></i>http://www.wjwillett.net</a></p><p><a href="https://scholar.google.ca/citations?user=Q17-rckAAAAJ" target="_blank"><i class="fas fa-graduation-cap fa-fw"></i>Google Scholar</a></p><div class="ui horizontal small divided link list"></div></div><div id="publications" class="category"><h1 class="ui horizontal divider header"><i class="file alternate outline icon"></i>Publications</h1><div class="ui segment" style="margin-top:50px"><div class="publication ui vertical segment stackable grid" data-id="chi-2023-dhawka"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2023-dhawka.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2023</span></p><p class="color" style="font-size:1.3em"><b>We are the Data: Challenges and Opportunities for Creating Demographically Diverse Anthropographics</b></p><p><a href="/people/priya-dhawka"><img src="/static/images/people/priya-dhawka.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Priya Dhawka</span></a> , <a href="/people/helen-ai-he"><img src="/static/images/people/helen-ai-he.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Helen Ai He</span></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Anthropographics</span><span class="ui brown basic label">Demographic Data</span><span class="ui brown basic label">Diversity</span><span class="ui brown basic label">Marginalized Populations</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-ea-2023-chulpongsatorn"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-ea-2023-chulpongsatorn.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI EA 2023</span></p><p class="color" style="font-size:1.3em"><b>HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies</b></p><p><a href="/people/neil-chulpongsatorn"><img src="/static/images/people/neil-chulpongsatorn.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Neil Chulpongsatorn</span></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <a href="/people/ryo-suzuki"><img src="/static/images/people/ryo-suzuki.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ryo Suzuki</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Mixed Reality</span><span class="ui brown basic label">Embedded Data Visualization</span><span class="ui brown basic label">Tangible Interaction</span><span class="ui brown basic label">Cross Device Interaction</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="gecco-2022-ivanov"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/gecco-2022-ivanov.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">GECCO 2022</span></p><p class="color" style="font-size:1.3em"><b>EvoIsland: Interactive Evolution via an Island-Inspired Spatial User Interface Framework</b></p><p><a href="/people/sasha-ivanov"><img src="/static/images/people/sasha-ivanov.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sasha Ivanov</span></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <span>Christian Jacob</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Interactive Evolutionary Systems</span><span class="ui brown basic label">User Interfaces</span><span class="ui brown basic label">Visualization</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="gi-2022-hull"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/gi-2022-hull.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">GI 2022</span></p><p class="color" style="font-size:1.3em"><b>Simultaneous Worlds: Supporting Fluid Exploration of Multiple Data Sets via Physical Models</b></p><p><a href="/people/carmen-hull"><img src="/static/images/people/carmen-hull.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Carmen Hull</span></a> , <a href="/people/soren-knudsen"><img src="/static/images/people/soren-knudsen.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Søren Knudsen</span></a> , <a href="/people/sheelagh-carpendale"><img src="/static/images/people/sheelagh-carpendale.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sheelagh Carpendale</span></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Interactive Surfaces</span><span class="ui brown basic label">Data Physicalization</span><span class="ui brown basic label">Architectural Models</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2022-bressa"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2022-bressa.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2022</span></p><p class="color" style="font-size:1.3em"><b>Data Every Day: Designing and Living with Personal Situated Visualizations</b></p><p><a href="/people/nathalie-bressa"><img src="/static/images/people/nathalie-bressa.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Nathalie Bressa</span></a> , <span>Jo Vermeulen</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Self Tracking</span><span class="ui brown basic label">Situated Visualization</span><span class="ui brown basic label">Personal Data</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2022-ivanov"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2022-ivanov.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2022</span></p><p class="color" style="font-size:1.3em"><b>One Week in the Future: Previs Design Futuring for HCI Research</b></p><p><a href="/people/sasha-ivanov"><img src="/static/images/people/sasha-ivanov.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sasha Ivanov</span></a> , <a href="/people/tim-au-yeung"><img src="/static/images/people/tim-au-yeung.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Tim Au Yeung</span></a> , <a href="/people/kathryn-blair"><img src="/static/images/people/kathryn-blair.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kathryn Blair</span></a> , <a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kurtis Danyluk</span></a> , <a href="/people/georgina-freeman"><img src="/static/images/people/georgina-freeman.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Georgina Freeman</span></a> , <a href="/people/marcus-friedel"><img src="/static/images/people/marcus-friedel.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Marcus Friedel</span></a> , <a href="/people/carmen-hull"><img src="/static/images/people/carmen-hull.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Carmen Hull</span></a> , <a href="/people/michael-hung"><img src="/static/images/people/michael-hung.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Michael Hung</span></a> , <a href="/people/sydney-pratte"><img src="/static/images/people/sydney-pratte.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sydney Pratte</span></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Design Futuring</span><span class="ui brown basic label">Prototyping</span><span class="ui brown basic label">Previsualization</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="ieee-2021-willett"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/ieee-2021-willett.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">IEEE 2021</span><span class="ui big basic pink label"><b><i class="fas fa-trophy"></i> Best Paper</b></span></p><p class="color" style="font-size:1.3em"><b>Perception! Immersion! Empowerment!: Superpowers as Inspiration for Visualization</b></p><p><a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <a href="/people/bon-adriel-aseniero"><img src="/static/images/people/bon-adriel-aseniero.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Bon Adriel Aseniero</span></a> , <a href="/people/sheelagh-carpendale"><img src="/static/images/people/sheelagh-carpendale.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sheelagh Carpendale</span></a> , <span>Pierre Dragicevic</span> , <span>Yvonne Jansen</span> , <a href="/people/lora-oehlberg"><img src="/static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a> , <span>Petra Isenberg</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Data Visualization</span><span class="ui brown basic label">Visualization</span><span class="ui brown basic label">Cognition</span><span class="ui brown basic label">Interactive Systems</span><span class="ui brown basic label">Tools</span><span class="ui brown basic label">Pragmatics</span><span class="ui brown basic label">Pattern Recognition</span><span class="ui brown basic label">Superpowers</span><span class="ui brown basic label">Empowerment</span><span class="ui brown basic label">Vision</span><span class="ui brown basic label">Perception</span><span class="ui brown basic label">Fiction</span><span class="ui brown basic label">Situated Visualization</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="dis-2021-wannamaker"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/dis-2021-wannamaker.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">DIS 2021</span></p><p class="color" style="font-size:1.3em"><b>I/O Bits: User-Driven, Situated, and Dedicated Self-Tracking</b></p><p><a href="/people/kendra-wannamaker"><img src="/static/images/people/kendra-wannamaker.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kendra Wannamaker</span></a> , <span>Sandeep Kollannur</span> , <span>Marian Dörk</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Personal Informatics</span><span class="ui brown basic label">Situated Visualization</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2021-danyluk"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2021-danyluk.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2021</span></p><p class="color" style="font-size:1.3em"><b>A Design Space Exploration of Worlds in Miniature</b></p><p><a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kurtis Danyluk</span></a> , <span>Barrett Ens</span> , <span>Bernhard Jenny</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Virtual Augmented Reality</span><span class="ui brown basic label">Meta Analysis Literature Survey</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2021-ens"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2021-ens.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2021</span></p><p class="color" style="font-size:1.3em"><b>Grand Challenges in Immersive Analytics</b></p><p><span>Barrett Ens</span> , <span>Benjamin Bach</span> , <span>Maxime Cordeil</span> , <span>Ulrich Engelke</span> , <span>Marcos Serrano</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <span>Arnaud Prouzeau</span> , <span>Christoph Anthes</span> , <span>Wolfgang Büschel</span> , <span>Cody Dunne</span> , <span>Tim Dwyer</span> , <span>Jens Grubert</span> , <span>Jason H. Haga</span> , <span>Nurit Kishenbaum</span> , <span>Dylan Kobayashi</span> , <span>Tica Lin</span> , <span>Monsurat Olaosebikan</span> , <span>Fabian Pointecker</span> , <span>David Saffo</span> , <span>Nazmus Saquib</span> , <span>Dieter Schmalsteig</span> , <span>Danielle Albers Szafir</span> , <span>Matthew Whitlock</span> , <span>Yalong Yang</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Immersive Analytics</span><span class="ui brown basic label">Grand Research Challenges</span><span class="ui brown basic label">Data Visualisation</span><span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Virtual Reality</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="gi-2021-mactavish"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/gi-2021-mactavish.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">GI 2021</span></p><p class="color" style="font-size:1.3em"><b>Perspective Charts</b></p><p><span>Mia MacTavish</span> , <span>Katayoon Etemad</span> , <span>Faramarz Samavati</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Information Visualization</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="cupum-2021-rout"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/cupum-2021-rout.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">Urban Informatics and Future Cities</span></p><p class="color" style="font-size:1.3em"><b>(Big) Data in Urban Design Practice: Supporting High-Level Design Tasks Using a Visualization of Human Movement Data from Smartphones</b></p><p><span>Angela Rout</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Smartphone Data</span><span class="ui brown basic label">GPS</span><span class="ui brown basic label">Data Visualization</span><span class="ui brown basic label">Architecture</span><span class="ui brown basic label">Urban Design</span><span class="ui brown basic label">Task Based Framework</span><span class="ui brown basic label">High Level Tasks</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2020-goffin"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2020-goffin.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2020</span></p><p class="color" style="font-size:1.3em"><b>Interaction Techniques for Visual Exploration Using Embedded Word-Scale Visualizations</b></p><p><span>Pascal Goffin</span> , <span>Tanja Blascheck</span> , <span>Petra Isenberg</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Glyphs</span><span class="ui brown basic label">Word Scale Visualization</span><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Interaction Techniques</span><span class="ui brown basic label">Text Visualization</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="tvcg-2019-walny"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tvcg-2019-walny.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">TVCG 2019</span><span class="ui big basic pink label"><b><i class="fas fa-trophy"></i> Best Paper</b></span></p><p class="color" style="font-size:1.3em"><b>Data Changes Everything: Challenges and Opportunities in Data Visualization Design Handoff</b></p><p><span>Jagoda Walny</span> , <a href="/people/christian-frisson"><img src="/static/images/people/christian-frisson.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Christian Frisson</span></a> , <span>Mieka West</span> , <span>Doris Kosminsky</span> , <a href="/people/soren-knudsen"><img src="/static/images/people/soren-knudsen.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Søren Knudsen</span></a> , <a href="/people/sheelagh-carpendale"><img src="/static/images/people/sheelagh-carpendale.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sheelagh Carpendale</span></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Design Handoff</span><span class="ui brown basic label">Data Mapping</span><span class="ui brown basic label">Design Process</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="dis-2019-bressa"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/dis-2019-bressa.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">DIS 2019</span></p><p class="color" style="font-size:1.3em"><b>Sketching and Ideation Activities for Situated Visualization Design</b></p><p><a href="/people/nathalie-bressa"><img src="/static/images/people/nathalie-bressa.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Nathalie Bressa</span></a> , <a href="/people/kendra-wannamaker"><img src="/static/images/people/kendra-wannamaker.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kendra Wannamaker</span></a> , <span>Henrik Korsgaard</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <span>Jo Vermeulen</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Ideation</span><span class="ui brown basic label">Design Workshops</span><span class="ui brown basic label">Situated Visualization</span><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Small Displays</span><span class="ui brown basic label">Sketching</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="tvcg-2019-blascheck"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tvcg-2019-blascheck.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">TVCG 2019</span></p><p class="color" style="font-size:1.3em"><b>Exploration Strategies for Discovery of Interactivity in Visualizations</b></p><p><span>Tanja Blascheck</span> , <span>Lindsay MacDonald Vermeulen</span> , <span>Jo Vermeulen</span> , <span>Charles Perin</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <span>Thomas Ertl</span> , <a href="/people/sheelagh-carpendale"><img src="/static/images/people/sheelagh-carpendale.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sheelagh Carpendale</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Discovery</span><span class="ui brown basic label">Visualization</span><span class="ui brown basic label">Open Data</span><span class="ui brown basic label">Evaluation</span><span class="ui brown basic label">Eye Tracking</span><span class="ui brown basic label">Interaction Logs</span><span class="ui brown basic label">Think Aloud</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2019-danyluk"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2019-danyluk.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2019</span><span class="ui big basic pink label"><b><i class="fas fa-award"></i> Honorable Mention</b></span></p><p class="color" style="font-size:1.3em"><b>Look-From Camera Control for 3D Terrain Maps</b></p><p><a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kurtis Danyluk</span></a> , <span>Bernhard Jenny</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Terrain</span><span class="ui brown basic label">Touch</span><span class="ui brown basic label">Map Interaction</span><span class="ui brown basic label">Look From Camera Control</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="vr-2019-satriadi"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/vr-2019-satriadi.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">IEEE VR 2019</span></p><p class="color" style="font-size:1.3em"><b>Augmented Reality Map Navigation with Freehand Gestures</b></p><p><span>Kadek Ananta Satriadi</span> , <span>Barrett Ens</span> , <span>Maxime Cordeil</span> , <span>Bernhard Jenny</span> , <span>Tobias Czauderna</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Gesture Recognition</span><span class="ui brown basic label">Human Computer Interaction</span><span class="ui brown basic label">Interactive Devices</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="cga-2019-ivanov"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/cga-2019-ivanov.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">IEEE CG&amp;A 2019</span></p><p class="color" style="font-size:1.3em"><b>A Walk Among the Data</b></p><p><span>Alexander Ivanov</span> , <a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kurtis Danyluk</span></a> , <span>Christian Jacob</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Data Visualization</span><span class="ui brown basic label">Visualization</span><span class="ui brown basic label">Art</span><span class="ui brown basic label">Tools</span><span class="ui brown basic label">Virtual Environments</span><span class="ui brown basic label">Two Dimensional Displays</span><span class="ui brown basic label">Anthropomorphism</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="sui-2017-li"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/sui-2017-li.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">SUI 2017</span></p><p class="color" style="font-size:1.3em"><b>Visibility Perception and Dynamic Viewsheds for Topographic Maps and Models</b></p><p><span>Nico Li</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <a href="/people/ehud-sharlin"><img src="/static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a> , <span>Mario Costa Sousa</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Terrain Visualization</span><span class="ui brown basic label">Geospatial Visualization</span><span class="ui brown basic label">Dynamic Viewshed</span><span class="ui brown basic label">Topographic Maps</span><span class="ui brown basic label">Tangible User Interfaces</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2017-aoki"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2017-aoki.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2017</span></p><p class="color" style="font-size:1.3em"><b>Environmental Protection and Agency: Motivations, Capacity, and Goals in Participatory Sensing</b></p><p><span>Paul Aoki</span> , <span>Allison Woodruff</span> , <span>Baladitya Yellapragada</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Citizen Science</span><span class="ui brown basic label">Environmental Sensing</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2017-hull"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2017-hull.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2017</span></p><p class="color" style="font-size:1.3em"><b>Building with Data: Architectural Models as Inspiration for Data Physicalization</b></p><p><a href="/people/carmen-hull"><img src="/static/images/people/carmen-hull.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Carmen Hull</span></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Design Process</span><span class="ui brown basic label">Architectural Models</span><span class="ui brown basic label">Data Physicalization</span><span class="ui brown basic label">Embodied Interaction</span><span class="ui brown basic label">Data Visualization</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="tvcg-2017-goffin"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tvcg-2017-goffin.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">TVCG 2017</span></p><p class="color" style="font-size:1.3em"><b>An Exploratory Study of Word-Scale Graphics in Data-Rich Text Documents</b></p><p><span>Pascal Goffin</span> , <span>Jeremy Boy</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <span>Petra Isenberg</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Word Scale Visualization</span><span class="ui brown basic label">Word Scale Graphic</span><span class="ui brown basic label">Text Visualization</span><span class="ui brown basic label">Sparklines</span><span class="ui brown basic label">Authoring Tool</span><span class="ui brown basic label">Information Visualization</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="tvcg-2017-willett"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tvcg-2017-willett.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">TVCG 2017</span></p><p class="color" style="font-size:1.3em"><b>Embedded Data Representations</b></p><p><a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <span>Yvonne Jansen</span> , <span>Pierre Dragicevic</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Data Physicalization</span><span class="ui brown basic label">Ambient Displays</span><span class="ui brown basic label">Ubiquitous Computing</span><span class="ui brown basic label">Augmented Reality</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2015-oehlberg"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2015-oehlberg.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2015</span></p><p class="color" style="font-size:1.3em"><b>Patterns of Physical Design Remixing in Online Maker Communities</b></p><p><a href="/people/lora-oehlberg"><img src="/static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <span>Wendy E. Mackay</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Customization</span><span class="ui brown basic label">Maker Communities</span><span class="ui brown basic label">User Innovation</span><span class="ui brown basic label">Collaboration</span><span class="ui brown basic label">Hacking</span><span class="ui brown basic label">Remixing</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2015-willett"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2015-willett.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2015</span></p><p class="color" style="font-size:1.3em"><b>Lightweight Relief Shearing for Enhanced Terrain Perception on Interactive Maps</b></p><p><a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <span>Bernhard Jenny</span> , <span>Tobias Isenberg</span> , <span>Pierre Dragicevic</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Plan Oblique Relief</span><span class="ui brown basic label">Interaction</span><span class="ui brown basic label">Depth Perception</span><span class="ui brown basic label">Terrain Maps</span><span class="ui brown basic label">Relief Shearing</span></div></p></div></div></div><div id="publications-modal"><div id="chi-2023-dhawka" class="ui large modal"><div class="header"><a href="/publications/chi-2023-dhawka" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2023-dhawka</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2023</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2023-dhawka.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2023-dhawka" target="_blank">We are the Data: Challenges and Opportunities for Creating Demographically Diverse Anthropographics</a></h1><p class="meta"><a href="/people/priya-dhawka"><img src="/static/images/people/priya-dhawka.jpg" class="ui circular spaced image mini-profile"/><strong>Priya Dhawka</strong></a> , <a href="/people/helen-ai-he"><img src="/static/images/people/helen-ai-he.jpg" class="ui circular spaced image mini-profile"/><strong>Helen Ai He</strong></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/chi-2023-dhawka.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2023-dhawka.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/iBzv2jS3ECM" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/iBzv2jS3ECM?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/iBzv2jS3ECM/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Anthropographics are human-shaped visualizations that aim to emphasize the human importance of datasets and the people behind them. However, current anthropographics tend to employ homogeneous human shapes to encode data about diverse demographic groups. Such anthropographics can obscure important differences between groups and contemporary designs exemplify the lack of inclusive approaches for representing human diversity in visualizations. In response, we explore the creation of demographically diverse anthropographics that communicate the visible diversity of demographically distinct populations. Building on previous anthropographics research, we explore strategies for visualizing datasets about people in ways that explicitly encode diversity—illustrating these approaches with examples in a variety of visual styles. We also critically reflect on strategies for creating diverse anthropographics, identifying social and technical challenges that can result in harmful representations. Finally, we highlight a set of forward-looking research opportunities for advancing the design and understanding of diverse anthropographics.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Anthropographics</span><span class="ui brown basic label">Demographic Data</span><span class="ui brown basic label">Diversity</span><span class="ui brown basic label">Marginalized Populations</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Priya Dhawka<!-- -->, <!-- -->Helen Ai He<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>We are the Data: Challenges and Opportunities for Creating Demographically Diverse Anthropographics</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;23)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->14<!-- -->.  DOI: <a href="https://doi.org/10.1145/3544548.3581086" target="_blank">https://doi.org/10.1145/3544548.3581086</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-ea-2023-chulpongsatorn" class="ui large modal"><div class="header"><a href="/publications/chi-ea-2023-chulpongsatorn" target="_blank"><i class="fas fa-link fa-fw"></i>chi-ea-2023-chulpongsatorn</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI EA 2023</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-ea-2023-chulpongsatorn.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-ea-2023-chulpongsatorn" target="_blank">HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies</a></h1><p class="meta"><a href="/people/neil-chulpongsatorn"><img src="/static/images/people/neil-chulpongsatorn.jpg" class="ui circular spaced image mini-profile"/><strong>Neil Chulpongsatorn</strong></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <a href="/people/ryo-suzuki"><img src="/static/images/people/ryo-suzuki.jpg" class="ui circular spaced image mini-profile"/><strong>Ryo Suzuki</strong></a></p><p><a href="/static/publications/chi-ea-2023-chulpongsatorn.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-ea-2023-chulpongsatorn.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We contribute interaction techniques for augmenting mixed reality (MR) visualizations with smartphone proxies. By combining head-mounted displays (HMDs) with mobile touchscreens, we can augment low-resolution holographic 3D charts with precise touch input, haptics feedback, high-resolution 2D graphics, and physical manipulation. Our approach aims to complement both MR and physical visualizations. Most current MR visualizations suffer from unreliable tracking, low visual resolution, and imprecise input. Data physicalizations on the other hand, although allowing for natural physical manipulation, are limited in dynamic and interactive modification. We demonstrate how mobile devices such as smartphones or tablets can serve as physical proxies for MR data interactions, creating dynamic visualizations that support precise manipulation and rich input and output. We describe 6 interaction techniques that leverage the combined physicality, sensing, and output capabilities of HMDs and smartphones, and demonstrate those interactions via a prototype system. Based on an evaluation, we outline opportunities for combining the advantages of both MR and physical charts.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Mixed Reality</span><span class="ui brown basic label">Embedded Data Visualization</span><span class="ui brown basic label">Tangible Interaction</span><span class="ui brown basic label">Cross Device Interaction</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Neil Chulpongsatorn<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Ryo Suzuki<!-- -->. <b>HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies</b>. <i>In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems (CHI EA &#x27;23)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->8<!-- -->.  DOI: <a href="https://doi.org/10.1145/3544549.3585738" target="_blank">https://doi.org/10.1145/3544549.3585738</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="gecco-2022-ivanov" class="ui large modal"><div class="header"><a href="/publications/gecco-2022-ivanov" target="_blank"><i class="fas fa-link fa-fw"></i>gecco-2022-ivanov</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">GECCO 2022</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/gecco-2022-ivanov.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/gecco-2022-ivanov" target="_blank">EvoIsland: Interactive Evolution via an Island-Inspired Spatial User Interface Framework</a></h1><p class="meta"><a href="/people/sasha-ivanov"><img src="/static/images/people/sasha-ivanov.jpg" class="ui circular spaced image mini-profile"/><strong>Sasha Ivanov</strong></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <span>Christian Jacob</span></p><p><a href="/static/publications/gecco-2022-ivanov.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>gecco-2022-ivanov.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We present EvoIsland, a scalable interactive evolutionary user interface framework inspired by the spatially isolated land masses seen on Earth. Our generalizable interaction system encourages creators to spatially explore a wide range of design possibilities through the combination, separation, and rearrangement of hexagonal tiles on a grid. As these tiles are grouped into islandlike clusters, localized populations of designs form through an underlying evolutionary system. The interactions that take place within EvoIsland provide content creators with new ways to shape, display and assess populations in evolutionary systems that produce a wide range of solutions with visual phenotype outputs.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Interactive Evolutionary Systems</span><span class="ui brown basic label">User Interfaces</span><span class="ui brown basic label">Visualization</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Sasha Ivanov<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Christian Jacob<!-- -->. <b>EvoIsland: Interactive Evolution via an Island-Inspired Spatial User Interface Framework</b>. <i>In undefined (GECCO &#x27;22)</i>. <!-- -->  Page: 1-<!-- -->8<!-- -->.  DOI: <a href="https://doi.org/10.1145/3512290.3528722" target="_blank">https://doi.org/10.1145/3512290.3528722</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="gi-2022-hull" class="ui large modal"><div class="header"><a href="/publications/gi-2022-hull" target="_blank"><i class="fas fa-link fa-fw"></i>gi-2022-hull</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">GI 2022</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/gi-2022-hull.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/gi-2022-hull" target="_blank">Simultaneous Worlds: Supporting Fluid Exploration of Multiple Data Sets via Physical Models</a></h1><p class="meta"><a href="/people/carmen-hull"><img src="/static/images/people/carmen-hull.jpg" class="ui circular spaced image mini-profile"/><strong>Carmen Hull</strong></a> , <a href="/people/soren-knudsen"><img src="/static/images/people/soren-knudsen.jpg" class="ui circular spaced image mini-profile"/><strong>Søren Knudsen</strong></a> , <a href="/people/sheelagh-carpendale"><img src="/static/images/people/sheelagh-carpendale.jpg" class="ui circular spaced image mini-profile"/><strong>Sheelagh Carpendale</strong></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/gi-2022-hull.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>gi-2022-hull.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We take the well-established use of physical scale models in architecture and identify new opportunities for using them to interactively visualize and examine multiple streams of geospatial data. Overlaying, comparing, or integrating visualizations of complementary data sets in the same physical space is often challenging given the constraints of various data types and the limited design space of possible visual encodings. Our vision of “simultaneous worlds” uses physical models as a substrate upon which visualizations of multiple data streams can be dynamically and concurrently integrated. To explore the potential of this concept, we created three design explorations that use an illuminated campus model to integrate visualizations about building energy use, climate, and movement paths on a university campus. We use a research through design approach, documenting how our interdisciplinary collaborations with domain experts, students, and architects informed our designs. Based on our observations, we characterize the benefits of models for 1) situating visualizations, 2) composing visualizations, and 3) manipulating and authoring visualizations. Our work highlights the potential of physical models to support embodied exploration of spatial and non-spatial visualizations through fluid interactions.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Interactive Surfaces</span><span class="ui brown basic label">Data Physicalization</span><span class="ui brown basic label">Architectural Models</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Carmen Hull<!-- -->, <!-- -->Søren Knudsen<!-- -->, <!-- -->Sheelagh Carpendale<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Simultaneous Worlds: Supporting Fluid Exploration of Multiple Data Sets via Physical Models</b>. <i>In undefined (GI &#x27;22)</i>. <!-- -->  Page: 1-<!-- -->10<!-- -->.  DOI: <a href="http://hdl.handle.net/1880/114742" target="_blank">http://hdl.handle.net/1880/114742</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2022-bressa" class="ui large modal"><div class="header"><a href="/publications/chi-2022-bressa" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2022-bressa</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2022</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2022-bressa.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2022-bressa" target="_blank">Data Every Day: Designing and Living with Personal Situated Visualizations</a></h1><p class="meta"><a href="/people/nathalie-bressa"><img src="/static/images/people/nathalie-bressa.jpg" class="ui circular spaced image mini-profile"/><strong>Nathalie Bressa</strong></a> , <span>Jo Vermeulen</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/chi-2022-bressa.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2022-bressa.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/B0bKMgDd1xY" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/B0bKMgDd1xY?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/B0bKMgDd1xY/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We explore the design and utility of situated manual self-tracking visualizations on dedicated displays that integrate data tracking into existing practices and physical environments. Situating self-tracking tools in relevant locations is a promising approach to enable reflection on and awareness of data without needing to rely on sensorized tracking or personal devices. In both a long-term autobiographical design process and a co-design study with six participants, we rapidly prototyped and deployed 30 situated self-tracking applications over a ten month period. Grounded in the experience of designing and living with these trackers, we contribute findings on logging and data entry, the use of situated displays, and the visual design and customization of trackers. Our results demonstrate the potential of customizable dedicated self-tracking visualizations that are situated in relevant physical spaces, and suggest future research opportunities and new potential applications for situated visualizations.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Self Tracking</span><span class="ui brown basic label">Situated Visualization</span><span class="ui brown basic label">Personal Data</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Nathalie Bressa<!-- -->, <!-- -->Jo Vermeulen<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Data Every Day: Designing and Living with Personal Situated Visualizations</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;22)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->18<!-- -->.  DOI: <a href="https://doi.org/10.1145/3491102.3517737" target="_blank">https://doi.org/10.1145/3491102.3517737</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2022-ivanov" class="ui large modal"><div class="header"><a href="/publications/chi-2022-ivanov" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2022-ivanov</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2022</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2022-ivanov.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2022-ivanov" target="_blank">One Week in the Future: Previs Design Futuring for HCI Research</a></h1><p class="meta"><a href="/people/sasha-ivanov"><img src="/static/images/people/sasha-ivanov.jpg" class="ui circular spaced image mini-profile"/><strong>Sasha Ivanov</strong></a> , <a href="/people/tim-au-yeung"><img src="/static/images/people/tim-au-yeung.jpg" class="ui circular spaced image mini-profile"/><strong>Tim Au Yeung</strong></a> , <a href="/people/kathryn-blair"><img src="/static/images/people/kathryn-blair.jpg" class="ui circular spaced image mini-profile"/><strong>Kathryn Blair</strong></a> , <a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><strong>Kurtis Danyluk</strong></a> , <a href="/people/georgina-freeman"><img src="/static/images/people/georgina-freeman.jpg" class="ui circular spaced image mini-profile"/><strong>Georgina Freeman</strong></a> , <a href="/people/marcus-friedel"><img src="/static/images/people/marcus-friedel.jpg" class="ui circular spaced image mini-profile"/><strong>Marcus Friedel</strong></a> , <a href="/people/carmen-hull"><img src="/static/images/people/carmen-hull.jpg" class="ui circular spaced image mini-profile"/><strong>Carmen Hull</strong></a> , <a href="/people/michael-hung"><img src="/static/images/people/michael-hung.jpg" class="ui circular spaced image mini-profile"/><strong>Michael Hung</strong></a> , <a href="/people/sydney-pratte"><img src="/static/images/people/sydney-pratte.jpg" class="ui circular spaced image mini-profile"/><strong>Sydney Pratte</strong></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/chi-2022-ivanov.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2022-ivanov.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/qoIwYW83iSU" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/qoIwYW83iSU?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/qoIwYW83iSU/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We explore the use of cinematic “pre-visualization” (previs) techniques as a rapid ideation and design futuring method for human computer interaction (HCI) research. Previs approaches, which are widely used in animation and film production, use digital design tools to create medium-fidelity videos that capture richer interaction, motion, and context than sketches or static illustrations. When used as a design futuring method, previs can facilitate rapid, iterative discussions that reveal tensions, challenges, and opportunities for new research. We performed eight one-week design futuring sprints, in which individual HCI researchers collaborated with a lead designer to produce concept sketches, storyboards, and videos that examined future applications of their research. From these experiences, we identify recurring themes and challenges and present a One Week Futuring Workbook that other researchers can use to guide their own futuring sprints. We also highlight how variations of our approach could support other speculative design practices.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Design Futuring</span><span class="ui brown basic label">Prototyping</span><span class="ui brown basic label">Previsualization</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Sasha Ivanov<!-- -->, <!-- -->Tim Au Yeung<!-- -->, <!-- -->Kathryn Blair<!-- -->, <!-- -->Kurtis Danyluk<!-- -->, <!-- -->Georgina Freeman<!-- -->, <!-- -->Marcus Friedel<!-- -->, <!-- -->Carmen Hull<!-- -->, <!-- -->Michael Hung<!-- -->, <!-- -->Sydney Pratte<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>One Week in the Future: Previs Design Futuring for HCI Research</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;22)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->15<!-- -->.  DOI: <a href="https://doi.org/10.1145/3491102.3517584" target="_blank">https://doi.org/10.1145/3491102.3517584</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="ieee-2021-willett" class="ui large modal"><div class="header"><a href="/publications/ieee-2021-willett" target="_blank"><i class="fas fa-link fa-fw"></i>ieee-2021-willett</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">IEEE 2021</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/ieee-2021-willett.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/ieee-2021-willett" target="_blank">Perception! Immersion! Empowerment!: Superpowers as Inspiration for Visualization</a></h1><p class="meta"><a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <a href="/people/bon-adriel-aseniero"><img src="/static/images/people/bon-adriel-aseniero.jpg" class="ui circular spaced image mini-profile"/><strong>Bon Adriel Aseniero</strong></a> , <a href="/people/sheelagh-carpendale"><img src="/static/images/people/sheelagh-carpendale.jpg" class="ui circular spaced image mini-profile"/><strong>Sheelagh Carpendale</strong></a> , <span>Pierre Dragicevic</span> , <span>Yvonne Jansen</span> , <a href="/people/lora-oehlberg"><img src="/static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a> , <span>Petra Isenberg</span></p><p><a href="/static/publications/ieee-2021-willett.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>ieee-2021-willett.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We explore how the lens of fictional superpowers can help characterize how visualizations empower people and provide inspiration for new visualization systems. Researchers and practitioners often tout visualizations&#x27; ability to “make the invisible visible” and to “enhance cognitive abilities.” Meanwhile superhero comics and other modern fiction often depict characters with similarly fantastic abilities that allow them to see and interpret the world in ways that transcend traditional human perception. We investigate the intersection of these domains, and show how the language of superpowers can be used to characterize existing visualization systems and suggest opportunities for new and empowering ones. We introduce two frameworks: The first characterizes seven underlying mechanisms that form the basis for a variety of visual superpowers portrayed in fiction. The second identifies seven ways in which visualization tools and interfaces can instill a sense of empowerment in the people who use them. Building on these observations, we illustrate a diverse set of “visualization superpowers” and highlight opportunities for the visualization community to create new systems and interactions that empower new experiences with data. Material and illustrations are available under CC-BY 4.0 at osf.io/8yhfz.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Data Visualization</span><span class="ui brown basic label">Visualization</span><span class="ui brown basic label">Cognition</span><span class="ui brown basic label">Interactive Systems</span><span class="ui brown basic label">Tools</span><span class="ui brown basic label">Pragmatics</span><span class="ui brown basic label">Pattern Recognition</span><span class="ui brown basic label">Superpowers</span><span class="ui brown basic label">Empowerment</span><span class="ui brown basic label">Vision</span><span class="ui brown basic label">Perception</span><span class="ui brown basic label">Fiction</span><span class="ui brown basic label">Situated Visualization</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Wesley Willett<!-- -->, <!-- -->Bon Adriel Aseniero<!-- -->, <!-- -->Sheelagh Carpendale<!-- -->, <!-- -->Pierre Dragicevic<!-- -->, <!-- -->Yvonne Jansen<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Petra Isenberg<!-- -->. <b>Perception! Immersion! Empowerment!: Superpowers as Inspiration for Visualization</b>. <i>In undefined (IEEE &#x27;21)</i>. <!-- -->  Page: 1-<!-- -->11<!-- -->.  DOI: <a href="10.1109/TVCG.2021.3114844" target="_blank">10.1109/TVCG.2021.3114844</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="dis-2021-wannamaker" class="ui large modal"><div class="header"><a href="/publications/dis-2021-wannamaker" target="_blank"><i class="fas fa-link fa-fw"></i>dis-2021-wannamaker</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">DIS 2021</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/dis-2021-wannamaker.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/dis-2021-wannamaker" target="_blank">I/O Bits: User-Driven, Situated, and Dedicated Self-Tracking</a></h1><p class="meta"><a href="/people/kendra-wannamaker"><img src="/static/images/people/kendra-wannamaker.jpg" class="ui circular spaced image mini-profile"/><strong>Kendra Wannamaker</strong></a> , <span>Sandeep Kollannur</span> , <span>Marian Dörk</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/dis-2021-wannamaker.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>dis-2021-wannamaker.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We present I/O Bits, a prototype personal informatics system that explores the potential for user-driven and situated self-tracking. With simple tactile inputs and small e-paper visualizations, I/O Bits are dedicated physical devices that allow individuals to track and visualize different kinds of personal activities in-situ. This is in contrast to most self-tracking systems, which automate data collection, centralize information displays, or integrate into multi-purpose devices like smartwatches or mobile phones. We report findings from an e-paper visualization workshop and a prototype deployment where participants constructed their own I/O Bits and used them to track a range of personal data. Based on these experiences, we contribute insights and opportunities for situated and user-driven personal informatics.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Personal Informatics</span><span class="ui brown basic label">Situated Visualization</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Kendra Wannamaker<!-- -->, <!-- -->Sandeep Kollannur<!-- -->, <!-- -->Marian Dörk<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>I/O Bits: User-Driven, Situated, and Dedicated Self-Tracking</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;21)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->10<!-- -->.  DOI: <a href="http://hdl.handle.net/1880/113555" target="_blank">http://hdl.handle.net/1880/113555</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/yhMKURtgFZ0" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/yhMKURtgFZ0?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/yhMKURtgFZ0/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2021-danyluk" class="ui large modal"><div class="header"><a href="/publications/chi-2021-danyluk" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2021-danyluk</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2021</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2021-danyluk.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2021-danyluk" target="_blank">A Design Space Exploration of Worlds in Miniature</a></h1><p class="meta"><a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><strong>Kurtis Danyluk</strong></a> , <span>Barrett Ens</span> , <span>Bernhard Jenny</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/chi-2021-danyluk.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2021-danyluk.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>Worlds-in-Miniature (WiMs) are interactive worlds within a world and combine the advantages of an input space, a cartographicmap, and an overview+detail interface. They have been used across the extended virtuality spectrum for a variety of applications.Building on an analysis of examples of WiMs from the research literature we contribute a design space for WiMs based on sevendesign dimensions. Further, we expand upon existing definitions of WiMs to provide a definition that applies across the extendedreality spectrum. We identify the design dimensions of size-scope-scale, abstraction, geometry, reference frame, links, multiples, andvirtuality. Using our framework we describe existing Worlds-in-Miniature from the research literature and reveal unexplored researchareas. Finally, we generate new examples of WiMs using our framework to fill some of these gaps. With our findings, we identifyopportunities that can guide future research into WiMs.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Virtual Augmented Reality</span><span class="ui brown basic label">Meta Analysis Literature Survey</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Kurtis Danyluk<!-- -->, <!-- -->Barrett Ens<!-- -->, <!-- -->Bernhard Jenny<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>A Design Space Exploration of Worlds in Miniature</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;21)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->20<!-- -->.  DOI: <a target="_blank"></a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2021-ens" class="ui large modal"><div class="header"><a href="/publications/chi-2021-ens" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2021-ens</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2021</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2021-ens.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2021-ens" target="_blank">Grand Challenges in Immersive Analytics</a></h1><p class="meta"><span>Barrett Ens</span> , <span>Benjamin Bach</span> , <span>Maxime Cordeil</span> , <span>Ulrich Engelke</span> , <span>Marcos Serrano</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <span>Arnaud Prouzeau</span> , <span>Christoph Anthes</span> , <span>Wolfgang Büschel</span> , <span>Cody Dunne</span> , <span>Tim Dwyer</span> , <span>Jens Grubert</span> , <span>Jason H. Haga</span> , <span>Nurit Kishenbaum</span> , <span>Dylan Kobayashi</span> , <span>Tica Lin</span> , <span>Monsurat Olaosebikan</span> , <span>Fabian Pointecker</span> , <span>David Saffo</span> , <span>Nazmus Saquib</span> , <span>Dieter Schmalsteig</span> , <span>Danielle Albers Szafir</span> , <span>Matthew Whitlock</span> , <span>Yalong Yang</span></p><p><a href="/static/publications/chi-2021-ens.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2021-ens.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>Immersive Analytics is a quickly evolving field that unites several areas such as visualisation, immersive environments, and human-computer interaction to support human data analysis with emerging technologies. This research has thrived over the past years with multiple workshops, seminars, and a growing body of publications, spanning several conferences. Given the rapid advancement of interaction technologies and novel application domains, this paper aims toward a broader research agenda to enable widespread adoption. We present 17 key research challenges developed over multiple sessions by a diverse group of 24 international experts, initiated from a virtual scientific workshop at ACM CHI 2020. These challenges aim to coordinate future work by providing a systematic roadmap of current directions and impending hurdles to facilitate productive and effective applications for Immersive Analytics.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Immersive Analytics</span><span class="ui brown basic label">Grand Research Challenges</span><span class="ui brown basic label">Data Visualisation</span><span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Virtual Reality</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Barrett Ens<!-- -->, <!-- -->Benjamin Bach<!-- -->, <!-- -->Maxime Cordeil<!-- -->, <!-- -->Ulrich Engelke<!-- -->, <!-- -->Marcos Serrano<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Arnaud Prouzeau<!-- -->, <!-- -->Christoph Anthes<!-- -->, <!-- -->Wolfgang Büschel<!-- -->, <!-- -->Cody Dunne<!-- -->, <!-- -->Tim Dwyer<!-- -->, <!-- -->Jens Grubert<!-- -->, <!-- -->Jason H. Haga<!-- -->, <!-- -->Nurit Kishenbaum<!-- -->, <!-- -->Dylan Kobayashi<!-- -->, <!-- -->Tica Lin<!-- -->, <!-- -->Monsurat Olaosebikan<!-- -->, <!-- -->Fabian Pointecker<!-- -->, <!-- -->David Saffo<!-- -->, <!-- -->Nazmus Saquib<!-- -->, <!-- -->Dieter Schmalsteig<!-- -->, <!-- -->Danielle Albers Szafir<!-- -->, <!-- -->Matthew Whitlock<!-- -->, <!-- -->Yalong Yang<!-- -->. <b>Grand Challenges in Immersive Analytics</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;21)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->17<!-- -->.  DOI: <a target="_blank"></a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="gi-2021-mactavish" class="ui large modal"><div class="header"><a href="/publications/gi-2021-mactavish" target="_blank"><i class="fas fa-link fa-fw"></i>gi-2021-mactavish</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">GI 2021</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/gi-2021-mactavish.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/gi-2021-mactavish" target="_blank">Perspective Charts</a></h1><p class="meta"><span>Mia MacTavish</span> , <span>Katayoon Etemad</span> , <span>Faramarz Samavati</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/gi-2021-mactavish.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>gi-2021-mactavish.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/Sp4Vt8mMhCs&amp;list=PLZQ0ePfDvRH4Ac7xfBdPlMQX0d0NYQ7Y-" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/Sp4Vt8mMhCs&amp;list=PLZQ0ePfDvRH4Ac7xfBdPlMQX0d0NYQ7Y-?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/Sp4Vt8mMhCs&amp;list=PLZQ0ePfDvRH4Ac7xfBdPlMQX0d0NYQ7Y-/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We introduce three novel data visualizations, called perspective charts, based on the concept of size constancy in linear perspective projection. Bar charts are a popular and commonly used tool for the interpretation of datasets, however, representing datasets with multi-scale variation is challenging in a bar chart due to limitations in viewing space. Each of our designs focuses on the static representation of datasets with large ranges with respect to important variations in the data. Through a user study, we measure the effectiveness of our designs for representing these datasets in comparison to traditional methods, such as a standard bar chart or a broken-axis bar chart, and state-of-the-art methods, such as a scale-stack bar chart. The evaluation reveals that our designs allow pieces of data to be visually compared at a level of accuracy similar to traditional visualizations. Our designs demonstrate advantages when compared to state-of-the-art visualizations designed to represent datasets with large outliers.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Information Visualization</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Mia MacTavish<!-- -->, <!-- -->Katayoon Etemad<!-- -->, <!-- -->Faramarz Samavati<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Perspective Charts</b>. <i>In undefined (GI &#x27;21)</i>. <!-- -->  Page: 1-<!-- -->10<!-- -->.  DOI: <a href="http://hdl.handle.net/1880/113671" target="_blank">http://hdl.handle.net/1880/113671</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="cupum-2021-rout" class="ui large modal"><div class="header"><a href="/publications/cupum-2021-rout" target="_blank"><i class="fas fa-link fa-fw"></i>cupum-2021-rout</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">Urban Informatics and Future Cities</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/cupum-2021-rout.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/cupum-2021-rout" target="_blank">(Big) Data in Urban Design Practice: Supporting High-Level Design Tasks Using a Visualization of Human Movement Data from Smartphones</a></h1><p class="meta"><span>Angela Rout</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/cupum-2021-rout.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>cupum-2021-rout.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/Me8cU6RoCiA" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/Me8cU6RoCiA?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/Me8cU6RoCiA/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We present the SmartCampus visualization tool, representing spatiotemporal data of over 200 student pathways and restpoints on a university campus. Based on our experiences with SmartCampus, we also propose a task-based framework that de-scribes how practicing urban designers (specifically, architects) can use human movement data visualizations in their work. Although extensive amounts of location data are produced daily by smartphones, existing geospatial tools are not customized to specifically support high-level urban design tasks. To help identify opportunities in urban design for visualizing human movement data from devices such as smartphones, we used our SmartCampus prototype to facilitate a series of 3 participatory design sessions (3 participants), a targeted online survey (14 participants), and semi-structured interviews (6 participants) with architectural experts. Our findings showcase the need for location analysis tools tailored to concrete urban design practices, and also highlight opportunities for Smart City researchers interested in developing domain specific, visualization tools.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Smartphone Data</span><span class="ui brown basic label">GPS</span><span class="ui brown basic label">Data Visualization</span><span class="ui brown basic label">Architecture</span><span class="ui brown basic label">Urban Design</span><span class="ui brown basic label">Task Based Framework</span><span class="ui brown basic label">High Level Tasks</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Angela Rout<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>(Big) Data in Urban Design Practice: Supporting High-Level Design Tasks Using a Visualization of Human Movement Data from Smartphones</b>. <i>In undefined (Urban Informatics and Future C &#x27;es)</i>. <!-- -->  Page: 1-<!-- -->301-318<!-- -->.  DOI: <a href="http://hdl.handle.net/1880/113114" target="_blank">http://hdl.handle.net/1880/113114</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2020-goffin" class="ui large modal"><div class="header"><a href="/publications/chi-2020-goffin" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2020-goffin</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2020</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2020-goffin.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2020-goffin" target="_blank">Interaction Techniques for Visual Exploration Using Embedded Word-Scale Visualizations</a></h1><p class="meta"><span>Pascal Goffin</span> , <span>Tanja Blascheck</span> , <span>Petra Isenberg</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/chi-2020-goffin.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2020-goffin.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/wPaVdSWM8hU" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/wPaVdSWM8hU?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/wPaVdSWM8hU/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We describe a design space of view manipulation interactions for small data-driven contextual visualizations (word-scale visualizations). These interaction techniques support an active reading experience and engage readers through exploration of embedded visualizations whose placement and content connect them to specific terms in a document. A reader could, for example, use our proposed interaction techniques to explore word-scale visualizations of stock market trends for companies listed in a market overview article. When readers wish to engage more deeply with the data, they can collect, arrange, compare, and navigate the document using the embedded word-scale visualizations, permitting more visualization-centric analyses. We support our design space with a concrete implementation, illustrate it with examples from three application domains, and report results from two experiments. The experiments show how view manipulation interactions helped readers examine embedded visualizations more quickly and with less scrolling and yielded qualitative feedback on usability and future opportunities.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Glyphs</span><span class="ui brown basic label">Word Scale Visualization</span><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Interaction Techniques</span><span class="ui brown basic label">Text Visualization</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Pascal Goffin<!-- -->, <!-- -->Tanja Blascheck<!-- -->, <!-- -->Petra Isenberg<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Interaction Techniques for Visual Exploration Using Embedded Word-Scale Visualizations</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;20)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3313831.3376842" target="_blank">https://doi.org/10.1145/3313831.3376842</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="tvcg-2019-walny" class="ui large modal"><div class="header"><a href="/publications/tvcg-2019-walny" target="_blank"><i class="fas fa-link fa-fw"></i>tvcg-2019-walny</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">TVCG 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tvcg-2019-walny.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/tvcg-2019-walny" target="_blank">Data Changes Everything: Challenges and Opportunities in Data Visualization Design Handoff</a></h1><p class="meta"><span>Jagoda Walny</span> , <a href="/people/christian-frisson"><img src="/static/images/people/christian-frisson.jpg" class="ui circular spaced image mini-profile"/><strong>Christian Frisson</strong></a> , <span>Mieka West</span> , <span>Doris Kosminsky</span> , <a href="/people/soren-knudsen"><img src="/static/images/people/soren-knudsen.jpg" class="ui circular spaced image mini-profile"/><strong>Søren Knudsen</strong></a> , <a href="/people/sheelagh-carpendale"><img src="/static/images/people/sheelagh-carpendale.jpg" class="ui circular spaced image mini-profile"/><strong>Sheelagh Carpendale</strong></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/tvcg-2019-walny.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>tvcg-2019-walny.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://player.vimeo.com/video/360483702" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://player.vimeo.com/video/360483702?autoplay=1&gt;&lt;img src=https://i.vimeocdn.com/video/814665539_640.webp&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Complex data visualization design projects often entail collaboration between people with different visualization-related skills. For example, many teams include both designers who create new visualization designs and developers who implement the resulting visualization software. We identify gaps between data characterization tools, visualization design tools, and development platforms that pose challenges for designer-developer teams working to create new data visualizations. While it is common for commercial interaction design tools to support collaboration between designers and developers, creating data visualizations poses several unique challenges that are not supported by current tools. In particular, visualization designers must characterize and build an understanding of the underlying data, then specify layouts, data encodings, and other data-driven parameters that will be robust across many different data values. In larger teams, designers must also clearly communicate these mappings and their dependencies to developers, clients, and other collaborators. We report observations and reflections from five large multidisciplinary visualization design projects and highlight six data-specific visualization challenges for design specification and handoff. These challenges include adapting to changing data, anticipating edge cases in data, understanding technical challenges, articulating data-dependent interactions, communicating data mappings, and preserving the integrity of data mappings across iterations. Based on these observations, we identify opportunities for future tools for prototyping, testing, and communicating data-driven designs, which might contribute to more successful and collaborative data visualization design.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Design Handoff</span><span class="ui brown basic label">Data Mapping</span><span class="ui brown basic label">Design Process</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Jagoda Walny<!-- -->, <!-- -->Christian Frisson<!-- -->, <!-- -->Mieka West<!-- -->, <!-- -->Doris Kosminsky<!-- -->, <!-- -->Søren Knudsen<!-- -->, <!-- -->Sheelagh Carpendale<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Data Changes Everything: Challenges and Opportunities in Data Visualization Design Handoff</b>. <i>In IEEE Transactions on Visualization and Computer Graphics (TVCG &#x27;19)</i>. <!-- -->IEEE, New York, NY, USA<!-- -->  Page: 1-<!-- -->10<!-- -->.  DOI: <a href="https://doi.org/10.1109/TVCG.2019.2934538" target="_blank">https://doi.org/10.1109/TVCG.2019.2934538</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://player.vimeo.com/video/368703151" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://player.vimeo.com/video/368703151?autoplay=1&gt;&lt;img src=https://i.vimeocdn.com/video/825448765_640.webp&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="dis-2019-bressa" class="ui large modal"><div class="header"><a href="/publications/dis-2019-bressa" target="_blank"><i class="fas fa-link fa-fw"></i>dis-2019-bressa</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">DIS 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/dis-2019-bressa.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/dis-2019-bressa" target="_blank">Sketching and Ideation Activities for Situated Visualization Design</a></h1><p class="meta"><a href="/people/nathalie-bressa"><img src="/static/images/people/nathalie-bressa.jpg" class="ui circular spaced image mini-profile"/><strong>Nathalie Bressa</strong></a> , <a href="/people/kendra-wannamaker"><img src="/static/images/people/kendra-wannamaker.jpg" class="ui circular spaced image mini-profile"/><strong>Kendra Wannamaker</strong></a> , <span>Henrik Korsgaard</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <span>Jo Vermeulen</span></p><p><a href="/static/publications/dis-2019-bressa.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>dis-2019-bressa.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We report on findings from seven design workshops that used ideation and sketching activities to prototype new situated visualizations - representations of data that are displayed in proximity to the physical referents (such as people, objects, and locations) to which the data is related. Designing situated visualizations requires a fine-grained understanding of the context in which the visualizations are placed, as well as an exploration of different options for placement and form factors, which existing methods for visualization design do not account for. Focusing on small displays as a target platform, we reflect on our experiences of using a diverse range of sketching activities, materials, and prompts. Based on these observations, we identify challenges and opportunities for sketching and ideating situated visualizations. We also outline the space of design activities for situated visualization and highlight promising methods for both designers and researchers.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Ideation</span><span class="ui brown basic label">Design Workshops</span><span class="ui brown basic label">Situated Visualization</span><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Small Displays</span><span class="ui brown basic label">Sketching</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Nathalie Bressa<!-- -->, <!-- -->Kendra Wannamaker<!-- -->, <!-- -->Henrik Korsgaard<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Jo Vermeulen<!-- -->. <b>Sketching and Ideation Activities for Situated Visualization Design</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;19)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->.  DOI: <a href="https://doi.org/10.1145/3322276.3322326" target="_blank">https://doi.org/10.1145/3322276.3322326</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="tvcg-2019-blascheck" class="ui large modal"><div class="header"><a href="/publications/tvcg-2019-blascheck" target="_blank"><i class="fas fa-link fa-fw"></i>tvcg-2019-blascheck</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">TVCG 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tvcg-2019-blascheck.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/tvcg-2019-blascheck" target="_blank">Exploration Strategies for Discovery of Interactivity in Visualizations</a></h1><p class="meta"><span>Tanja Blascheck</span> , <span>Lindsay MacDonald Vermeulen</span> , <span>Jo Vermeulen</span> , <span>Charles Perin</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <span>Thomas Ertl</span> , <a href="/people/sheelagh-carpendale"><img src="/static/images/people/sheelagh-carpendale.jpg" class="ui circular spaced image mini-profile"/><strong>Sheelagh Carpendale</strong></a></p><p><a href="/static/publications/tvcg-2019-blascheck.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>tvcg-2019-blascheck.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://player.vimeo.com/video/289789025" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://player.vimeo.com/video/289789025?autoplay=1&gt;&lt;img src=https://i.vimeocdn.com/video/725516359_640.webp&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We investigate how people discover the functionality of an interactive visualization that was designed for the general public. While interactive visualizations are increasingly available for public use, we still know little about how the general public discovers what they can do with these visualizations and what interactions are available. Developing a better understanding of this discovery process can help inform the design of visualizations for the general public, which in turn can help make data more accessible. To unpack this problem, we conducted a lab study in which participants were free to use their own methods to discover the functionality of a connected set of interactive visualizations of public energy data. We collected eye movement data and interaction logs as well as video and audio recordings. By analyzing this combined data, we extract exploration strategies that the participants employed to discover the functionality in these interactive visualizations. These exploration strategies illuminate possible design directions for improving the discoverability of a visualization&#x27;s functionality.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Discovery</span><span class="ui brown basic label">Visualization</span><span class="ui brown basic label">Open Data</span><span class="ui brown basic label">Evaluation</span><span class="ui brown basic label">Eye Tracking</span><span class="ui brown basic label">Interaction Logs</span><span class="ui brown basic label">Think Aloud</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Tanja Blascheck<!-- -->, <!-- -->Lindsay MacDonald Vermeulen<!-- -->, <!-- -->Jo Vermeulen<!-- -->, <!-- -->Charles Perin<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Thomas Ertl<!-- -->, <!-- -->Sheelagh Carpendale<!-- -->. <b>Exploration Strategies for Discovery of Interactivity in Visualizations</b>. <i>In IEEE Transactions on Visualization and Computer Graphics (TVCG &#x27;19)</i>. <!-- -->IEEE, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1109/TVCG.2018.2802520" target="_blank">https://doi.org/10.1109/TVCG.2018.2802520</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2019-danyluk" class="ui large modal"><div class="header"><a href="/publications/chi-2019-danyluk" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2019-danyluk</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2019-danyluk.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2019-danyluk" target="_blank">Look-From Camera Control for 3D Terrain Maps</a></h1><p class="meta"><a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><strong>Kurtis Danyluk</strong></a> , <span>Bernhard Jenny</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/chi-2019-danyluk.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2019-danyluk.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We introduce three lightweight interactive camera control techniques for 3D terrain maps on touch devices based on a look-from metaphor (Discrete Look-From-At, Continuous Look-From-Forwards, and Continuous Look-From-Towards). These techniques complement traditional touch screen pan, zoom, rotate, and pitch controls allowing viewers to quickly transition between top-down, oblique, and ground-level views. We present the results of a study in which we asked participants to perform elevation comparison and line-of-sight determination tasks using each technique. Our results highlight how look-from techniques can be integrated on top of current direct manipulation navigation approaches by combining several direct manipulation operations into a single look-from operation. Additionally, they show how look-from techniques help viewers complete a variety of common and challenging map-based tasks.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Terrain</span><span class="ui brown basic label">Touch</span><span class="ui brown basic label">Map Interaction</span><span class="ui brown basic label">Look From Camera Control</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Kurtis Danyluk<!-- -->, <!-- -->Bernhard Jenny<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Look-From Camera Control for 3D Terrain Maps</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;19)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->12<!-- -->.  DOI: <a href="https://doi.org/10.1145/3290605.3300594" target="_blank">https://doi.org/10.1145/3290605.3300594</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="vr-2019-satriadi" class="ui large modal"><div class="header"><a href="/publications/vr-2019-satriadi" target="_blank"><i class="fas fa-link fa-fw"></i>vr-2019-satriadi</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">IEEE VR 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/vr-2019-satriadi.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/vr-2019-satriadi" target="_blank">Augmented Reality Map Navigation with Freehand Gestures</a></h1><p class="meta"><span>Kadek Ananta Satriadi</span> , <span>Barrett Ens</span> , <span>Maxime Cordeil</span> , <span>Bernhard Jenny</span> , <span>Tobias Czauderna</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/vr-2019-satriadi.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>vr-2019-satriadi.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/TE6AJEu8zdY" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/TE6AJEu8zdY?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/TE6AJEu8zdY/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Freehand gesture interaction has long been proposed as a `natural&#x27; input method for Augmented Reality (AR) applications, yet has been little explored for intensive applications like multiscale navigation. In multiscale navigation, such as digital map navigation, pan and zoom are the predominant interactions. A position-based input mapping (e.g. grabbing metaphor) is intuitive for such interactions, but is prone to arm fatigue. This work focuses on improving digital map navigation in AR with mid-air hand gestures, using a horizontal intangible map display. First, we conducted a user study to explore the effects of handedness (unimanual and bimanual) and input mapping (position-based and rate-based). From these findings we designed DiveZoom and TerraceZoom, two novel hybrid techniques that smoothly transition between position- and rate-based mappings. A second user study evaluated these designs. Our results indicate that the introduced input-mapping transitions can reduce perceived arm fatigue with limited impact on performance.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Gesture Recognition</span><span class="ui brown basic label">Human Computer Interaction</span><span class="ui brown basic label">Interactive Devices</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Kadek Ananta Satriadi<!-- -->, <!-- -->Barrett Ens<!-- -->, <!-- -->Maxime Cordeil<!-- -->, <!-- -->Bernhard Jenny<!-- -->, <!-- -->Tobias Czauderna<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Augmented Reality Map Navigation with Freehand Gestures</b>. <i>In undefined (IEEE VR &#x27;19)</i>. <!-- -->  Page: 1-<!-- -->11<!-- -->.  DOI: <a href="https://doi.org/10.1109/VR.2019.8798340" target="_blank">https://doi.org/10.1109/VR.2019.8798340</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/jNeEbB3sTn0" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/jNeEbB3sTn0?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/jNeEbB3sTn0/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="cga-2019-ivanov" class="ui large modal"><div class="header"><a href="/publications/cga-2019-ivanov" target="_blank"><i class="fas fa-link fa-fw"></i>cga-2019-ivanov</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">IEEE CG&amp;A 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/cga-2019-ivanov.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/cga-2019-ivanov" target="_blank">A Walk Among the Data</a></h1><p class="meta"><span>Alexander Ivanov</span> , <a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><strong>Kurtis Danyluk</strong></a> , <span>Christian Jacob</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/cga-2019-ivanov.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>cga-2019-ivanov.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We examine the potential for immersive unit visualizations—interactive virtual environments populated with objects representing individual items in a dataset. Our virtual reality prototype highlights how immersive unit visualizations can allow viewers to examine data at multiple scales, support immersive exploration, and create affective personal experiences with data.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Data Visualization</span><span class="ui brown basic label">Visualization</span><span class="ui brown basic label">Art</span><span class="ui brown basic label">Tools</span><span class="ui brown basic label">Virtual Environments</span><span class="ui brown basic label">Two Dimensional Displays</span><span class="ui brown basic label">Anthropomorphism</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Alexander Ivanov<!-- -->, <!-- -->Kurtis Danyluk<!-- -->, <!-- -->Christian Jacob<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>A Walk Among the Data</b>. <i>In undefined (IEEE CG&amp;A &#x27;19)</i>. <!-- -->  Page: 1-<!-- -->9<!-- -->.  DOI: <a href="http://dx.doi.org/10.1109/MCG.2019.2898941" target="_blank">http://dx.doi.org/10.1109/MCG.2019.2898941</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="sui-2017-li" class="ui large modal"><div class="header"><a href="/publications/sui-2017-li" target="_blank"><i class="fas fa-link fa-fw"></i>sui-2017-li</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">SUI 2017</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/sui-2017-li.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/sui-2017-li" target="_blank">Visibility Perception and Dynamic Viewsheds for Topographic Maps and Models</a></h1><p class="meta"><span>Nico Li</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <a href="/people/ehud-sharlin"><img src="/static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a> , <span>Mario Costa Sousa</span></p><p><a href="/static/publications/sui-2017-li.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>sui-2017-li.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://player.vimeo.com/video/275404995" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://player.vimeo.com/video/275404995?autoplay=1&gt;&lt;img src=https://i.vimeocdn.com/video/707686230_640.webp&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We compare the effectiveness of 2D maps and 3D terrain models for visibility tasks and demonstrate how interactive dynamic viewsheds can improve performance for both types of terrain representations. In general, the two-dimensional nature of classic topographic maps limits their legibility and can make complex yet typical cartographic tasks like determining the visibility between locations difficult. Both 3D physical models and interactive techniques like dynamic viewsheds have the potential to improve viewers&#x27; understanding of topography, but their impact has not been deeply explored. We evaluate the effectiveness of 2D maps, 3D models, and interactive viewsheds for both simple and complex visibility tasks. Our results demonstrate the benefits of the dynamic viewshed technique and highlight opportunities for additional tactile interactions. Based on these findings we present guidelines for improving the design and usability of future topographic maps and models.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Terrain Visualization</span><span class="ui brown basic label">Geospatial Visualization</span><span class="ui brown basic label">Dynamic Viewshed</span><span class="ui brown basic label">Topographic Maps</span><span class="ui brown basic label">Tangible User Interfaces</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Nico Li<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Ehud Sharlin<!-- -->, <!-- -->Mario Costa Sousa<!-- -->. <b>Visibility Perception and Dynamic Viewsheds for Topographic Maps and Models</b>. <i>In undefined (SUI &#x27;17)</i>. <!-- -->  Page: 1-<!-- -->9<!-- -->.  DOI: <a href="https://doi.org/10.1145/3131277.3132178" target="_blank">https://doi.org/10.1145/3131277.3132178</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/aVXUojoQF60" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/aVXUojoQF60?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/aVXUojoQF60/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2017-aoki" class="ui large modal"><div class="header"><a href="/publications/chi-2017-aoki" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2017-aoki</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2017</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2017-aoki.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2017-aoki" target="_blank">Environmental Protection and Agency: Motivations, Capacity, and Goals in Participatory Sensing</a></h1><p class="meta"><span>Paul Aoki</span> , <span>Allison Woodruff</span> , <span>Baladitya Yellapragada</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/chi-2017-aoki.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2017-aoki.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>In this paper we consider various genres of citizen science from the perspective of citizen participants. As a mode of scientific inquiry, citizen science has the potential to &quot;scale up&quot; scientific data collection efforts and increase lay engagement with science. However, current technological directions risk losing sight of the ways in which citizen science is actually practiced. As citizen science is increasingly used to describe a wide range of activities, we begin by presenting a framework of citizen science genres. We then present findings from four interlocking qualitative studies and technological interventions of community air quality monitoring efforts, examining the motivations and capacities of citizen participants and characterizing their alignment with different types of citizen science. Based on these studies, we suggest that data acquisition involves complex multi-dimensional tradeoffs, and the commonly held view that citizen science systems are a win-win for citizens and science may be overstated.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Citizen Science</span><span class="ui brown basic label">Environmental Sensing</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Paul Aoki<!-- -->, <!-- -->Allison Woodruff<!-- -->, <!-- -->Baladitya Yellapragada<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Environmental Protection and Agency: Motivations, Capacity, and Goals in Participatory Sensing</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;17)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3025453.3025667" target="_blank">https://doi.org/10.1145/3025453.3025667</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2017-hull" class="ui large modal"><div class="header"><a href="/publications/chi-2017-hull" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2017-hull</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2017</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2017-hull.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2017-hull" target="_blank">Building with Data: Architectural Models as Inspiration for Data Physicalization</a></h1><p class="meta"><a href="/people/carmen-hull"><img src="/static/images/people/carmen-hull.jpg" class="ui circular spaced image mini-profile"/><strong>Carmen Hull</strong></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/chi-2017-hull.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2017-hull.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/bkqLNgYIXek" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/bkqLNgYIXek?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/bkqLNgYIXek/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>In this paper we analyze the role of physical scale models in the architectural design process and apply insights from architecture for the creation and use of data physicalizations. Based on a survey of the architecture literature on model making and ten interviews with practicing architects, we describe the role of physical models as a tool for exploration and communication. From these observations, we identify trends in the use of physical models in architecture, which have the potential to inform the design of data physicalizations. We identify four functions of architectural modeling that can be directly adapted for use in the process of building rich data models. Finally, we discuss how the visualization community can apply observations from architecture to the design of new data physicalizations.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Design Process</span><span class="ui brown basic label">Architectural Models</span><span class="ui brown basic label">Data Physicalization</span><span class="ui brown basic label">Embodied Interaction</span><span class="ui brown basic label">Data Visualization</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Carmen Hull<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Building with Data: Architectural Models as Inspiration for Data Physicalization</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;17)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->12<!-- -->.  DOI: <a href="https://doi.org/10.1145/3025453.3025850" target="_blank">https://doi.org/10.1145/3025453.3025850</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="tvcg-2017-goffin" class="ui large modal"><div class="header"><a href="/publications/tvcg-2017-goffin" target="_blank"><i class="fas fa-link fa-fw"></i>tvcg-2017-goffin</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">TVCG 2017</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tvcg-2017-goffin.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/tvcg-2017-goffin" target="_blank">An Exploratory Study of Word-Scale Graphics in Data-Rich Text Documents</a></h1><p class="meta"><span>Pascal Goffin</span> , <span>Jeremy Boy</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <span>Petra Isenberg</span></p><p><a href="/static/publications/tvcg-2017-goffin.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>tvcg-2017-goffin.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://player.vimeo.com/video/230834366" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://player.vimeo.com/video/230834366?autoplay=1&gt;&lt;img src=https://i.vimeocdn.com/video/651490206_640.webp&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We contribute an investigation of the design and function of word-scale graphics and visualizations embedded in text documents. Word-scale graphics include both data-driven representations such as word-scale visualizations and sparklines, and non-data-driven visual marks. Their design, function, and use has so far received little research attention. We present the results of an open ended exploratory study with nine graphic designers. The study resulted in a rich collection of different types of graphics, data provenance, and relationships between text, graphics, and data. Based on this corpus, we present a systematic overview of word-scale graphic designs, and examine how designers used them. We also discuss the designers&#x27; goals in creating their graphics, and characterize how they used word-scale graphics to visualize data, add emphasis, and create alternative narratives. Building on these examples, we discuss implications for the design of authoring tools for word-scale graphics and visualizations, and explore how new authoring environments could make it easier for designers to integrate them into documents.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Word Scale Visualization</span><span class="ui brown basic label">Word Scale Graphic</span><span class="ui brown basic label">Text Visualization</span><span class="ui brown basic label">Sparklines</span><span class="ui brown basic label">Authoring Tool</span><span class="ui brown basic label">Information Visualization</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Pascal Goffin<!-- -->, <!-- -->Jeremy Boy<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Petra Isenberg<!-- -->. <b>An Exploratory Study of Word-Scale Graphics in Data-Rich Text Documents</b>. <i>In IEEE Transactions on Visualization and Computer Graphics (TVCG &#x27;17)</i>. <!-- -->IEEE, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1109/TVCG.2016.2618797" target="_blank">https://doi.org/10.1109/TVCG.2016.2618797</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="tvcg-2017-willett" class="ui large modal"><div class="header"><a href="/publications/tvcg-2017-willett" target="_blank"><i class="fas fa-link fa-fw"></i>tvcg-2017-willett</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">TVCG 2017</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tvcg-2017-willett.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/tvcg-2017-willett" target="_blank">Embedded Data Representations</a></h1><p class="meta"><a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <span>Yvonne Jansen</span> , <span>Pierre Dragicevic</span></p><p><a href="/static/publications/tvcg-2017-willett.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>tvcg-2017-willett.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://player.vimeo.com/video/182971005" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://player.vimeo.com/video/182971005?autoplay=1&gt;&lt;img src=https://i.vimeocdn.com/video/592033369_640.webp&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We introduce embedded data representations, the use of visual and physical representations of data that are deeply integrated with the physical spaces, objects, and entities to which the data refers. Technologies like lightweight wireless displays, mixed reality hardware, and autonomous vehicles are making it increasingly easier to display data in-context. While researchers and artists have already begun to create embedded data representations, the benefits, trade-offs, and even the language necessary to describe and compare these approaches remain unexplored. In this paper, we formalize the notion of physical data referents – the real-world entities and spaces to which data corresponds – and examine the relationship between referents and the visual and physical representations of their data. We differentiate situated representations, which display data in proximity to data referents, and embedded representations, which display data so that it spatially coincides with data referents. Drawing on examples from visualization, ubiquitous computing, and art, we explore the role of spatial indirection, scale, and interaction for embedded representations. We also examine the tradeoffs between non-situated, situated, and embedded data displays, including both visualizations and physicalizations. Based on our observations, we identify a variety of design challenges for embedded data representation, and suggest opportunities for future research and applications.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Data Physicalization</span><span class="ui brown basic label">Ambient Displays</span><span class="ui brown basic label">Ubiquitous Computing</span><span class="ui brown basic label">Augmented Reality</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Wesley Willett<!-- -->, <!-- -->Yvonne Jansen<!-- -->, <!-- -->Pierre Dragicevic<!-- -->. <b>Embedded Data Representations</b>. <i>In IEEE Transactions on Visualization and Computer Graphics (TVCG &#x27;17)</i>. <!-- -->IEEE, New York, NY, USA<!-- -->  Page: 1-<!-- -->10<!-- -->.  DOI: <a href="https://doi.org/10.1109/TVCG.2016.2598608" target="_blank">https://doi.org/10.1109/TVCG.2016.2598608</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/ZS7lU60xChI" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/ZS7lU60xChI?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/ZS7lU60xChI/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2015-oehlberg" class="ui large modal"><div class="header"><a href="/publications/chi-2015-oehlberg" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2015-oehlberg</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2015</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2015-oehlberg.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2015-oehlberg" target="_blank">Patterns of Physical Design Remixing in Online Maker Communities</a></h1><p class="meta"><a href="/people/lora-oehlberg"><img src="/static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <span>Wendy E. Mackay</span></p><p><a href="/static/publications/chi-2015-oehlberg.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2015-oehlberg.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>Makers participate in remixing culture by drawing inspiration from, combining, and adapting designs for physical objects. To examine how makers remix each others&#x27; designs on a community scale, we analyzed metadata from over 175,000 digital designs from Thingiverse, the largest online design community for digital fabrication. Remixed designs on Thingiverse are predominantly generated designs from Customizer a built-in web app for adjusting parametric designs. However, we find that these designs do not elicit subsequent user activity and the authors who generate them tend not to contribute additional content to Thingiverse. Outside of Customizer, influential sources of remixing include complex assemblies and design primitives, as well as non-physical resources posing as physical designs. Building on our findings, we discuss ways in which online maker communities could become more than just design repositories and better support collaborative remixing.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Customization</span><span class="ui brown basic label">Maker Communities</span><span class="ui brown basic label">User Innovation</span><span class="ui brown basic label">Collaboration</span><span class="ui brown basic label">Hacking</span><span class="ui brown basic label">Remixing</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Lora Oehlberg<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Wendy E. Mackay<!-- -->. <b>Patterns of Physical Design Remixing in Online Maker Communities</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;15)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->12<!-- -->.  DOI: <a href="https://doi.org/10.1145/2702123.2702175" target="_blank">https://doi.org/10.1145/2702123.2702175</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/vJrVjH04nGc" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/vJrVjH04nGc?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/vJrVjH04nGc/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2015-willett" class="ui large modal"><div class="header"><a href="/publications/chi-2015-willett" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2015-willett</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2015</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2015-willett.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2015-willett" target="_blank">Lightweight Relief Shearing for Enhanced Terrain Perception on Interactive Maps</a></h1><p class="meta"><a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <span>Bernhard Jenny</span> , <span>Tobias Isenberg</span> , <span>Pierre Dragicevic</span></p><p><a href="/static/publications/chi-2015-willett.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2015-willett.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/YW31lmzQzpc" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/YW31lmzQzpc?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/YW31lmzQzpc/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We explore interactive relief shearing, a set of non-intrusive, direct manipulation interactions that expose depth and shape information in terrain maps using ephemeral animations. Reading and interpreting topography and relief on terrain maps is an important aspect of map use, but extracting depth information from 2D maps is notoriously difficult. Modern mapping software attempts to alleviate this limitation by presenting digital terrain using 3D views. However, 3D views introduce occlusion, complicate distance estimations, and typically require more complex interactions. In contrast, our approach reveals depth information via shearing animations on 2D maps, and can be paired with existing interactions such as pan and zoom. We examine explicit, integrated, and hybrid interactions for triggering relief shearing and present a version that uses device tilt to control depth effects. Our evaluation shows that these interactive techniques improve depth perception when compared to standard 2D and perspective views.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Plan Oblique Relief</span><span class="ui brown basic label">Interaction</span><span class="ui brown basic label">Depth Perception</span><span class="ui brown basic label">Terrain Maps</span><span class="ui brown basic label">Relief Shearing</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Wesley Willett<!-- -->, <!-- -->Bernhard Jenny<!-- -->, <!-- -->Tobias Isenberg<!-- -->, <!-- -->Pierre Dragicevic<!-- -->. <b>Lightweight Relief Shearing for Enhanced Terrain Perception on Interactive Maps</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;15)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->10<!-- -->.  DOI: <a href="https://doi.org/10.1145/2702123.2702172" target="_blank">https://doi.org/10.1145/2702123.2702172</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div></div></div></div><div class="one wide column"></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><img style="max-width:180px;margin:30px auto" src="/static/images/logo-6.png"/><div class="content"><img style="max-width:200px;margin:0px auto" src="/static/images/logo-4.png"/><div class="sub header">Department of Computer Science</div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"dataManager":"[]","props":{"pageProps":{"id":"wesley-willett"}},"page":"/person","query":{"id":"wesley-willett"},"buildId":"K2hp6SO31UL_wodvuo4Go","dynamicBuildId":false,"nextExport":true}</script><script async="" id="__NEXT_PAGE__/person" src="/_next/static/K2hp6SO31UL_wodvuo4Go/pages/person.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/K2hp6SO31UL_wodvuo4Go/pages/_app.js"></script><script src="/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" async=""></script><script src="/_next/static/chunks/commons.2ccf7861fac39e850a30.js" async=""></script><script src="/_next/static/runtime/main-ceb4d64d798d2348aa74.js" async=""></script></body></html>