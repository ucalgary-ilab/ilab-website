<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="format-detection" content="telephone=no"/><link href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.css" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/css/lightbox.css" rel="stylesheet"/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link href="/static/css/style.css" rel="stylesheet"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox-plus-jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              $('.ui.sidebar')
                .sidebar('attach events', '.sidebar.icon')

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><title class="next-head">Look-From Camera Control for 3D Terrain Maps | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="terrain, touch, map interaction, look-from camera control" class="next-head"/><meta name="description" content="We introduce three lightweight interactive camera control techniques for 3D terrain maps on touch devices based on a look-from metaphor (Discrete Look-From-At, Continuous Look-From-Forwards, and Continuous Look-From-Towards). These techniques complement traditional touch screen pan, zoom, rotate, and pitch controls allowing viewers to quickly transition between top-down, oblique, and ground-level views. We present the results of a study in which we asked participants to perform elevation comparison and line-of-sight determination tasks using each technique. Our results highlight how look-from techniques can be integrated on top of current direct manipulation navigation approaches by combining several direct manipulation operations into a single look-from operation. Additionally, they show how look-from techniques help viewers complete a variety of common and challenging map-based tasks." class="next-head"/><meta property="og:title" content="Look-From Camera Control for 3D Terrain Maps | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta property="og:description" content="We introduce three lightweight interactive camera control techniques for 3D terrain maps on touch devices based on a look-from metaphor (Discrete Look-From-At, Continuous Look-From-Forwards, and Continuous Look-From-Towards). These techniques complement traditional touch screen pan, zoom, rotate, and pitch controls allowing viewers to quickly transition between top-down, oblique, and ground-level views. We present the results of a study in which we asked participants to perform elevation comparison and line-of-sight determination tasks using each technique. Our results highlight how look-from techniques can be integrated on top of current direct manipulation navigation approaches by combining several direct manipulation operations into a single look-from operation. Additionally, they show how look-from techniques help viewers complete a variety of common and challenging map-based tasks." class="next-head"/><meta property="og:site_name" content="University of Calgary Interactions Lab" class="next-head"/><meta property="og:url" content="https://ilab.ucalgary.ca/" class="next-head"/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/chi-2019-danyluk.jpg" class="next-head"/><meta property="og:type" content="website" class="next-head"/><meta name="twitter:title" content="Look-From Camera Control for 3D Terrain Maps | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta name="twitter:description" content="We introduce three lightweight interactive camera control techniques for 3D terrain maps on touch devices based on a look-from metaphor (Discrete Look-From-At, Continuous Look-From-Forwards, and Continuous Look-From-Towards). These techniques complement traditional touch screen pan, zoom, rotate, and pitch controls allowing viewers to quickly transition between top-down, oblique, and ground-level views. We present the results of a study in which we asked participants to perform elevation comparison and line-of-sight determination tasks using each technique. Our results highlight how look-from techniques can be integrated on top of current direct manipulation navigation approaches by combining several direct manipulation operations into a single look-from operation. Additionally, they show how look-from techniques help viewers complete a variety of common and challenging map-based tasks." class="next-head"/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/chi-2019-danyluk.jpg" class="next-head"/><meta name="twitter:card" content="summary" class="next-head"/><meta name="twitter:site" content="@ucalgary" class="next-head"/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" class="next-head"/><link rel="preload" href="/_next/static/K2hp6SO31UL_wodvuo4Go/pages/publication.js" as="script"/><link rel="preload" href="/_next/static/K2hp6SO31UL_wodvuo4Go/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.2ccf7861fac39e850a30.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-ceb4d64d798d2348aa74.js" as="script"/></head><body><div id="__next"><div><div><div class="ui right vertical sidebar menu"><a class="item" href="/">Home</a><a class="item active" href="/publications">Publications</a><a class="item" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a></div><div class="ui stackable secondary pointing container menu" style="border-bottom:none;margin-right:15%;font-size:1.1em"><div class="left menu"><a class="item" href="/"><b>UCalgary iLab</b></a></div><div class="right menu"><a class="item active" href="/publications">Publications</a><a class="item" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a><div class="toc item"><a href="/"><b>UCalgary iLab</b></a><i style="float:right" class="sidebar icon"></i></div></div></div></div><div class="ui stackable grid"><div class="one wide column"></div><div class="ten wide column centered" style="margin-top:30px"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2019-danyluk.jpg"/></div><div class="thirteen wide column"><h1>Look-From Camera Control for 3D Terrain Maps</h1><p class="meta"><a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><strong>Kurtis Danyluk</strong></a> , <span>Bernhard Jenny</span> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="/static/publications/chi-2019-danyluk.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2019-danyluk.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We introduce three lightweight interactive camera control techniques for 3D terrain maps on touch devices based on a look-from metaphor (Discrete Look-From-At, Continuous Look-From-Forwards, and Continuous Look-From-Towards). These techniques complement traditional touch screen pan, zoom, rotate, and pitch controls allowing viewers to quickly transition between top-down, oblique, and ground-level views. We present the results of a study in which we asked participants to perform elevation comparison and line-of-sight determination tasks using each technique. Our results highlight how look-from techniques can be integrated on top of current direct manipulation navigation approaches by combining several direct manipulation operations into a single look-from operation. Additionally, they show how look-from techniques help viewers complete a variety of common and challenging map-based tasks.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Terrain</span><span class="ui brown basic label">Touch</span><span class="ui brown basic label">Map Interaction</span><span class="ui brown basic label">Look From Camera Control</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Kurtis Danyluk<!-- -->, <!-- -->Bernhard Jenny<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Look-From Camera Control for 3D Terrain Maps</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;19)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->12<!-- -->.  DOI: <a href="https://doi.org/10.1145/3290605.3300594" target="_blank">https://doi.org/10.1145/3290605.3300594</a></p></div></div></div></div><div class="one wide column"></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><img style="max-width:180px;margin:30px auto" src="/static/images/logo-6.png"/><div class="content"><img style="max-width:200px;margin:0px auto" src="/static/images/logo-4.png"/><div class="sub header">Department of Computer Science</div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"dataManager":"[]","props":{"pageProps":{"id":"chi-2019-danyluk"}},"page":"/publication","query":{"id":"chi-2019-danyluk"},"buildId":"K2hp6SO31UL_wodvuo4Go","dynamicBuildId":false,"nextExport":true}</script><script async="" id="__NEXT_PAGE__/publication" src="/_next/static/K2hp6SO31UL_wodvuo4Go/pages/publication.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/K2hp6SO31UL_wodvuo4Go/pages/_app.js"></script><script src="/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" async=""></script><script src="/_next/static/chunks/commons.2ccf7861fac39e850a30.js" async=""></script><script src="/_next/static/runtime/main-ceb4d64d798d2348aa74.js" async=""></script></body></html>